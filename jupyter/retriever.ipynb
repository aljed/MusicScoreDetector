{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "PNG_PATH = 'C:\\\\Users\\\\user\\\\Downloads\\\\deep_scores_dense\\\\deep_scores_dense\\\\images_png'\r\n",
    "XML_PATH = 'C:\\\\Users\\\\user\\\\Downloads\\\\deep_scores_dense\\\\deep_scores_dense\\\\xml_annotations'\r\n",
    "CONVERTED_PATH = 'C:\\\\Users\\\\user\\\\Downloads\\\\deep_scores_dense\\\\deep_scores_dense\\\\converted'\r\n",
    "CLASSES_PATH = 'C:\\\\Users\\\\user\\\\Downloads\\\\deep_scores_dense\\\\deep_scores_dense\\\\meta_info'\r\n",
    "X = 100\r\n",
    "Y = 100\r\n",
    "PARTS_NUMBER = 100\r\n",
    "ELEMENTS_MAX_NUMBER = 10"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\r\n",
    "import imageio as im\r\n",
    "import random\r\n",
    "import numpy as np\r\n",
    "from dataclasses import dataclass\r\n",
    "import xml.etree.ElementTree as ET\r\n",
    "\r\n",
    "random.seed()\r\n",
    "\r\n",
    "@dataclass\r\n",
    "class PartData:\r\n",
    "    slice: list\r\n",
    "    y: int\r\n",
    "    x: int\r\n",
    "    max_y: int\r\n",
    "    max_x: int\r\n",
    "\r\n",
    "def split_image(filename):\r\n",
    "    \r\n",
    "    image = np.array(im.imread(PNG_PATH + \"\\\\\" + filename))\r\n",
    "    shape = np.shape(image)\r\n",
    "    max_y = shape[0] - Y\r\n",
    "    max_x = shape[1] - X\r\n",
    "    parts = []\r\n",
    "    \r\n",
    "    for i in range(PARTS_NUMBER):\r\n",
    "        random_y = random.randrange(max_y)\r\n",
    "        random_x = random.randrange(max_x)\r\n",
    "        slice = image[random_y:random_y + Y, random_x:random_x + X, 0]\r\n",
    "        parts.append(PartData(slice, random_y, random_x, shape[0], shape[1]))\r\n",
    "        \r\n",
    "    return parts"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "@dataclass\r\n",
    "class BoundingBox:\r\n",
    "    xmin: float\r\n",
    "    xmax: float\r\n",
    "    ymin: float\r\n",
    "    ymax: float\r\n",
    "        \r\n",
    "    def is_within(self, bb):\r\n",
    "        return bb.xmin <= self.xmin and bb.xmax >= self.xmax and bb.ymin <= self.ymin and bb.ymax >= self.ymax\r\n",
    "\r\n",
    "    def get_normalized(self, x, y):\r\n",
    "        return BoundingBox(self.xmin/x, self.xmax/x, self.ymin/y, self.ymax/y)\r\n",
    "\r\n",
    "    def serialize(self):\r\n",
    "        return np.array(self.xmin, self.xmax, self.ymin, self.ymax)\r\n",
    "\r\n",
    "def retrieve_class_names():\r\n",
    "    files = os.listdir(CLASSES_PATH)\r\n",
    "    counter = 0\r\n",
    "    names = {}\r\n",
    "    for f in files:\r\n",
    "        names[f.replace('.csv', '')] = counter\r\n",
    "        counter += 1\r\n",
    "    return names\r\n",
    "\r\n",
    "classes = retrieve_class_names()\r\n",
    "\r\n",
    "@dataclass\r\n",
    "class Element:\r\n",
    "    typ: str\r\n",
    "    bounding_box: BoundingBox   \r\n",
    "\r\n",
    "    def serlialize(self):\r\n",
    "        prob_list = np.zeros([len(classes)])\r\n",
    "        prob_list[classes[self.typ]] = 1.0\r\n",
    "        return np.array(prob_list, self.bounding_box.serialize(), list(1))\r\n",
    "\r\n",
    "def serialize_element_list(elements):\r\n",
    "    output_array = []\r\n",
    "    for i in range(ELEMENTS_MAX_NUMBER - len(elements)):\r\n",
    "        elements.append(\r\n",
    "            Element()\r\n",
    "        )\r\n",
    "    for e in elements:\r\n",
    "        output_array.append(e.serialize)\r\n",
    "    return np.array(output_array)\r\n",
    "\r\n",
    "class Page:\r\n",
    "\r\n",
    "    def __init__(self, name):\r\n",
    "        self.name = name\r\n",
    "        self.elements = []\r\n",
    "        \r\n",
    "    def add(self, element):\r\n",
    "        self.elements.append(element)\r\n",
    "        \r\n",
    "    def retrieve_from_box(self, bb):\r\n",
    "        filtered = []\r\n",
    "        for e in self.elements:\r\n",
    "            if e.is_within(bb):\r\n",
    "                filtered.append(e)\r\n",
    "        return filtered\r\n",
    "\r\n",
    "    \r\n",
    "class Retriever:\r\n",
    "    \r\n",
    "    def retrieve():\r\n",
    "\r\n",
    "        files = os.listdir(XML_PATH)\r\n",
    "        pages = {}\r\n",
    "        num_of_files = len(files)\r\n",
    "        counter = 1\r\n",
    "\r\n",
    "        for f in files:\r\n",
    "\r\n",
    "            if counter % 100 == 0:\r\n",
    "                print(f'{round(counter*100/num_of_files)}% of the files processed, we are at {counter} in {num_of_files}.')\r\n",
    "            counter += 1\r\n",
    "            page = Page(f)\r\n",
    "            tree = ET.parse(XML_PATH + \"\\\\\" + f)\r\n",
    "            root = tree.getroot()\r\n",
    "\r\n",
    "            for obj in root.iter('object'):\r\n",
    "\r\n",
    "                raw_bb = obj.find('bndbox')\r\n",
    "                page.add(BoundingBox(\r\n",
    "                    float(raw_bb.find('xmin').text),\r\n",
    "                    float(raw_bb.find('xmax').text),\r\n",
    "                    float(raw_bb.find('ymin').text),\r\n",
    "                    float(raw_bb.find('ymax').text)\r\n",
    "                ))\r\n",
    "\r\n",
    "            pages[f] = page\r\n",
    "\r\n",
    "        return pages         "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pages = Retriever.retrieve() "
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import tensorflow as tf\r\n",
    "\r\n",
    "model = tf.keras.models.Sequential([\r\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(100,100,1)),\r\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\r\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\r\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\r\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu'),\r\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\r\n",
    "    tf.keras.layers.Flatten(),\r\n",
    "    tf.keras.layers.Dense(1024, activation='relu'),\r\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\r\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "# Get generator of da\r\n",
    "\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import matplotlib.image as mpimg\r\n",
    "\r\n",
    "@dataclass\r\n",
    "class Data:\r\n",
    "    img: list\r\n",
    "    elements: list\r\n",
    "\r\n",
    "    def to_ts(self):\r\n",
    "        return (self.img, serialize_element_list(self.elements))\r\n",
    "\r\n",
    "def generator(files):\r\n",
    "    for file in files:\r\n",
    "        splitted = split_image(file)\r\n",
    "        page = pages[file.replace(\".png\", \".xml\")]\r\n",
    "        for s in splitted:\r\n",
    "            data = Data(s.slice, page.retrieve_from_box(BoundingBox(s.x / s.max_x, (s.x + X) / s.max_x, s.y / s.max_y, (s.y + Y) / s.max_y)))\r\n",
    "            yield data.to_ts()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "files = os.listdir(PNG_PATH)\r\n",
    "ds = tf.data.Dataset.from_generator(generator, args=files, output_types=(tf.int32, tf.)\r\n"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "Either `output_signature` or `output_types` must be specified",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14056/213889250.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfiles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPNG_PATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    533\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m                 instructions)\n\u001b[1;32m--> 535\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mfrom_generator\u001b[1;34m(generator, output_types, output_shapes, args, output_signature)\u001b[0m\n\u001b[0;32m    891\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    892\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0moutput_types\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 893\u001b[1;33m         raise TypeError(\"Either `output_signature` or `output_types` must \"\n\u001b[0m\u001b[0;32m    894\u001b[0m                         \"be specified\")\n\u001b[0;32m    895\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Either `output_signature` or `output_types` must be specified"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "interpreter": {
   "hash": "247ab06e135bb35fa78c5eff31b2a9a0050dcb5fb773c2631d2a29ac689eeccb"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}