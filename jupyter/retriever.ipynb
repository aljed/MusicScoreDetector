{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "import random\n",
    "import data\n",
    "import os\n",
    "import parameters as p\n",
    "import tensorflow as tf\n",
    "import importlib"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "<module 'data' from 'C:\\\\Users\\\\user\\\\PycharmProjects\\\\nuty5\\\\jupyter\\\\data.py'>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(p)\n",
    "importlib.reload(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "random.seed()\n",
    "classes = data.retrieve_class_names()\n",
    "output_dim = p.ELEMENTS_MAX_NUMBER * (5 + len(classes))\n",
    "pages = data.Retriever().retrieve(classes)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5% of the files processed, we are at 100 in 1864.\n",
      "11% of the files processed, we are at 200 in 1864.\n",
      "16% of the files processed, we are at 300 in 1864.\n",
      "21% of the files processed, we are at 400 in 1864.\n",
      "27% of the files processed, we are at 500 in 1864.\n",
      "32% of the files processed, we are at 600 in 1864.\n",
      "38% of the files processed, we are at 700 in 1864.\n",
      "43% of the files processed, we are at 800 in 1864.\n",
      "48% of the files processed, we are at 900 in 1864.\n",
      "54% of the files processed, we are at 1000 in 1864.\n",
      "59% of the files processed, we are at 1100 in 1864.\n",
      "64% of the files processed, we are at 1200 in 1864.\n",
      "70% of the files processed, we are at 1300 in 1864.\n",
      "75% of the files processed, we are at 1400 in 1864.\n",
      "80% of the files processed, we are at 1500 in 1864.\n",
      "86% of the files processed, we are at 1600 in 1864.\n",
      "91% of the files processed, we are at 1700 in 1864.\n",
      "97% of the files processed, we are at 1800 in 1864.\n"
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "files = os.listdir(p.PNG_PATH)\n",
    "generator = data.Generator(pages, output_dim, classes)\n",
    "ds = tf.data.Dataset.from_generator(\n",
    "    generator.generator,\n",
    "    args=[files],\n",
    "    output_types=(tf.int32, tf.float32),\n",
    "    output_shapes=([p.BATCH_SIZE, p.Y, p.X, 3], [p.BATCH_SIZE, output_dim]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def get_loss(y_actual,y_pred):\n",
    "\n",
    "    y_actual_reshaped = K.reshape(y_actual, [p.BATCH_SIZE * p.ELEMENTS_MAX_NUMBER, -1])\n",
    "    y_pred_reshaped = K.reshape(y_pred, [p.BATCH_SIZE * p.ELEMENTS_MAX_NUMBER, -1])\n",
    "\n",
    "    main_probs_act = y_actual_reshaped[..., :1]\n",
    "    main_probs_pred = y_pred_reshaped[..., :1]\n",
    "    bb_probs_act = y_actual_reshaped[..., 1:5]\n",
    "    bb_probs_pred =  y_pred_reshaped[..., 1:5]\n",
    "    classes_probs_act = y_actual_reshaped[..., 5:]\n",
    "    classes_probs_pred =  y_pred_reshaped[..., 5:]\n",
    "\n",
    "    loss = K.sum(K.binary_crossentropy(main_probs_act, main_probs_pred, from_logits=True))\n",
    "    loss += K.sum(K.sum(K.abs(bb_probs_act - bb_probs_pred), 1) * main_probs_act)\n",
    "    loss += K.sum(K.sum(K.abs(classes_probs_act - classes_probs_pred), 1) * main_probs_act)\n",
    "\n",
    "    return loss\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "top = tf.keras.models.Sequential([\n",
    "    # tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(p.Y,p.X,1)),\n",
    "    # tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(1024, activation='relu'),\n",
    "    tf.keras.layers.Dense(1024, activation='relu')\n",
    "])\n",
    "\n",
    "vgg = tf.keras.applications.vgg19.VGG19(\n",
    "    include_top=False, weights='imagenet',\n",
    "    input_shape=(p.Y,p.X,3), pooling='avg'\n",
    ")\n",
    "\n",
    "model = tf.keras.Sequential(vgg.layers)\n",
    "model.add(tf.keras.layers.Dense(output_dim, activation='relu'))\n",
    "#model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=get_loss,\n",
    "              metrics=tf.keras.metrics.MeanAbsoluteError(name=\"mean_absolute_error\", dtype=None))\n",
    "a = model. fit(ds, epochs=1)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9/Unknown - 151s 17s/step - loss: 364.8649 - mean_absolute_error: 6965096.5000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
     ]
    }
   ],
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import imageio as im\n",
    "# image = np.array(im.imread(r'C:\\Users\\user\\Desktop\\ex2.png'))\n",
    "# pred = model.predict(np.reshape(image[0:p.X,0:p.X,0:3] / 255, (1, p.Y, p.X, 3)))\n",
    "# pred *=p.X\n",
    "\n",
    "aa = generator.generator(files).__next__()\n",
    "aaa = model.predict(aa[0])\n",
    "#print(aa[1],aaa )\n",
    "np.sum(np.abs(aaa - aa[1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a = aa[0][0]\n",
    "import viewer as v\n",
    "v.show_prediction(aa[1][0], aa[0][0])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "interpreter": {
   "hash": "247ab06e135bb35fa78c5eff31b2a9a0050dcb5fb773c2631d2a29ac689eeccb"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}